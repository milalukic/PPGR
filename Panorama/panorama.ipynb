{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9301057c-4528-49b5-a093-70175e88cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/mila/.local/lib/python3.10/site-packages (from opencv-contrib-python) (1.26.4)\n",
      "Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install opencv-python\n",
    "# !pip install imutils\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbf733e-8731-4d09-a0fb-36aa05eeddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f970806-8397-4cef-b9f3-aca0de04f1a9",
   "metadata": {},
   "source": [
    "## The Panorama Class\n",
    "**stitch_together** is the main function of the Panorama class, which handles the creation of a panoramic image by stitching two images together. \n",
    "This is the breakdown of its steps:\n",
    "\n",
    "1. It extract the keypoints and feature descriptors for  each of them by using the *find* function. This captures points in each image that can be matched afterwards in order to align them.\n",
    "   - The find function converts the image to grayscale, and then uses SIFT (Scale-Invariant Feature Transform) to detect keypoints and features. Converting to grayscale simplifies the image by removing color information, focusing solely on the intensity variations, which are key for detecting stable keypoints and features across different scales and rotations.\n",
    "3. It uses the *match_points* function to match these extracted keypoints based on their features. It uses the brute force method first (K Nearest Neighbors for k=2), and then filters them using Lowe's ratio test. \n",
    "- Lowe’s ratio test is a technique used in computer vision to filter out unreliable matches between keypoints in two images. By comparing the distances of the two closest matches for each keypoint, the test accepts a match only if the closest match is significantly closer than the second-closest one (by a factor given by \"ratio\"). This helps reduce false positives, as it indicates the best match is distinct enough to be reliable.\n",
    "5. If enough matches are found, it calculates a homography matrix, which describes the transformation needed to align the images.\n",
    "6. It uses the function *draw_matched* to draw matched points between the images and identifies the leftmost matched point in order to determine the width of the panorama\n",
    "7. It generates the panorama by wrapping the perspective of one of the images using the homography matrix and stitches it with the other image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f7c49c-e4e2-4001-a032-3f3296d1d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Panorama:\n",
    "    def stitch_together(self, imgs, ratio=0.75):\n",
    "        (img_left, img_right) = imgs\n",
    "        (points_left, features_left) = self.find(img_left)\n",
    "        (points_right, features_right) = self.find(img_right)\n",
    "\n",
    "        # Matching the corresponding points on pictures, determining\n",
    "        # the matrix M with RANSAC.\n",
    "        M = self.match_points(points_right, points_left, features_right, features_left, ratio)\n",
    "\n",
    "        # Wrong format / not enough points to pair them up.\n",
    "        if M is None:\n",
    "            return None\n",
    "\n",
    "        (pairs, homography_matrix, points) = M\n",
    "\n",
    "        # Drawing the matched points and find the leftmost detected point.\n",
    "        (pair_img, min_point) = self.draw_matched(img_right, img_left, points_right, points_left, pairs, points)\n",
    "\n",
    "        # Calculate panorama width\n",
    "        panorama_width = self.width(img_right.shape[1], img_left.shape[1], min_point)\n",
    "\n",
    "        # Form the panorama by warping the right image\n",
    "        panorama = cv2.warpPerspective(img_right, homography_matrix, (panorama_width, img_right.shape[0]))\n",
    "        panorama[0:img_left.shape[0], 0:img_left.shape[1]] = img_left\n",
    "        return (panorama, pair_img)\n",
    "\n",
    "\n",
    "    def find(self, img):\n",
    "        # Convert to greyscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        feature = cv2.SIFT_create()\n",
    "        (points, features) = feature.detectAndCompute(img, None)\n",
    "        points = np.float32([point.pt for point in points])\n",
    "        return (points, features)    \n",
    "\n",
    "    def match_points(self, points_right, points_left, features_right, features_left, ratio):\n",
    "        # Initial matches (Brute force - K Nearest Neighbours for k=2).\n",
    "        matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "        initial_matches = matcher.knnMatch(features_right, features_left, k=2)\n",
    "    \n",
    "        # Filtering by using Lowe's ratio test\n",
    "        matches = [\n",
    "            (match[0].trainIdx, match[0].queryIdx)\n",
    "            for match in initial_matches\n",
    "            if len(match) == 2 and match[0].distance < match[1].distance*ratio\n",
    "        ]\n",
    "\n",
    "        if len(matches) >= 4:\n",
    "            points_right_filtered = np.float32([points_right[i] for (_, i) in matches])\n",
    "            points_left_filtered = np.float32([points_left[i] for (i, _) in matches])\n",
    "                \n",
    "            # Calculating the correct points by using RANSAC and DLT algorithm\n",
    "            _, points = cv2.findHomography(points_right_filtered, points_left_filtered, cv2.RANSAC, 4.0)\n",
    "            M = self.DLT_normalized(points_right_filtered, points_left_filtered, points)\n",
    "            \n",
    "            return matches, M, points\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def draw_matched(self, img_right, img_left, points_right, points_left, matches, points):\n",
    "        # Stitching the images together\n",
    "        height, width_l, width_r = max(img_left.shape[0], img_right.shape[0]), img_left.shape[1], img_right.shape[1]\n",
    "\n",
    "        pair_img = np.zeros((height, width_l+width_r, 3), dtype=\"uint8\")\n",
    "        pair_img[0:img_left.shape[0], 0:width_l] = img_left\n",
    "        pair_img[0:img_right.shape[0], width_l:] = img_right\n",
    "\n",
    "        min_point = (width_l + width_r, 0)\n",
    "\n",
    "        for ((i, j), point) in zip(matches, points):\n",
    "            point_l = tuple(map(int, points_left[i]))\n",
    "            point_d = (int(points_right[j][0] + width_l), int(points_right[j][1]))\n",
    "\n",
    "            # Colors based on correctness\n",
    "            color = (0, 0, 255) if point == 1 else (255, 0, 0)\n",
    "            cv2.circle(pair_img, point_l, radius=0, color=color, thickness=3)\n",
    "            cv2.circle(pair_img, point_d, radius=0, color=color, thickness=3)\n",
    "\n",
    "            # Leftmost point\n",
    "            if point == 1 and point_l[0] < min_point[0]:\n",
    "                min_point = point_l\n",
    "\n",
    "        return pair_img, min_point\n",
    "\n",
    "    # Helper functions\n",
    "    def width(self, width_r, width_l, min_point):\n",
    "        return width_r + width_l - (width_l - min_point[0])\n",
    "\n",
    "    def normalize_matrix(self, M):\n",
    "        if M[2][2] != 1 and M[2][2] != 0:\n",
    "            M = M/M[2][2]\n",
    "        return M\n",
    "\n",
    "    # Calculating the 2x9 matrix based on the lemmas of DLT algorithm\n",
    "    def dlt_lemma(self, M, N):\n",
    "        M = np.array([M[0], M[1], 1])\n",
    "        N = np.array([N[0], N[1], 1])\n",
    "        return [\n",
    "            [0, 0, 0, -N[2] * M[0], -N[2] * M[1], -N[2] * M[2], N[1] * M[0], N[1] * M[1], N[1] * M[2]],\n",
    "            [N[2] * M[0], N[2] * M[1], N[2] * M[2], 0, 0, 0, -N[0] * M[0], -N[0] * M[1], -N[0] * M[2]]\n",
    "        ]\n",
    "\n",
    "    def DLT(self, origs, imgs):\n",
    "        M = []\n",
    "        for orig, img in zip(origs, imgs):\n",
    "            m = self.dlt_lemma(orig, img)\n",
    "            M.extend(m)\n",
    "        _, _, V = np.linalg.svd(M)\n",
    "        return self.normalize_matrix(V[-1].reshape(3, 3))\n",
    "\n",
    "    def normalize(self, points):\n",
    "        X, Y = np.mean(points, axis=0)\n",
    "        G = [[1, 0, -X], [0, 1, -Y], [0, 0, 1]]\n",
    "        r = np.mean(np.sqrt((points - [X, Y]) ** 2).sum(axis=1))\n",
    "        S = [[math.sqrt(2) / r, 0, 0], [0, math.sqrt(2) / r, 0], [0, 0, 1]]\n",
    "        return np.dot(S, G)\n",
    "\n",
    "    def DLT_normalized(self, origs, imgs, points):\n",
    "        T = self.normalize(origs)\n",
    "        TP = self.normalize(imgs)\n",
    "        originals = [np.dot(T, [o[0], o[1], 1])[:2] for o, t in zip(origs, points) if t]\n",
    "        images = [np.dot(TP, [s[0], s[1], 1])[:2] for s, t in zip(imgs, points) if t]\n",
    "        PP = self.DLT(originals, images)\n",
    "        return self.normalize_matrix(np.dot(np.dot(np.linalg.inv(TP), PP), T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f57389-c492-4d3d-98be-afd5089995b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load\n",
    "    left = cv2.imread('left.jpg')\n",
    "    right = cv2.imread('right.jpg')\n",
    "    # Make the panorama\n",
    "    panorama = Panorama()\n",
    "    (result, match) = panorama.stitch_together([left, right])\n",
    "    # Prikaz rezultata\n",
    "    cv2.imshow(\"Prva slika\", left)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow(\"Druga slika\", right)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow(\"Tacke preklapanja\", match)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow(\"Panorama\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace82b6-4d9f-46c1-b047-ec48b338747d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09467d3e-d04f-407f-bb05-8d4021fab1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
